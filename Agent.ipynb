{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782e5f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain langgraph langchain_openai langchainhub langsmith duckduckgo-search beautifulsoup4 gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fd6ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install getpass4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02357f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "open_ai_api_key=getpass.getpass(\"Enter your open ai api key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f93779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9411f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using summary node\n",
    "\n",
    "import functools, operator, requests, os, json\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "import gradio as gr\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph Research Agents\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\",api_key=open_ai_api_key)\n",
    "\n",
    "\n",
    "@tool(\"internet_search\", return_direct=False)\n",
    "def internet_search(query: str) -> str:\n",
    "    \"\"\"Searches the internet using DuckDuckGo.\"\"\"\n",
    "    with DDGS() as ddgs:\n",
    "        results = [r for r in ddgs.text(query, max_results=5)]\n",
    "        return results if results else \"No results found.\"\n",
    "\n",
    "@tool(\"process_content\", return_direct=False)\n",
    "def process_content(url: str) -> str:\n",
    "    \"\"\"Processes content from a webpage.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "tools = [internet_search, process_content]\n",
    "\n",
    "\n",
    "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "\n",
    "members = [\"Web_Searcher\", \"Insight_Researcher\",\"Summariser\"]\n",
    "system_prompt = (\n",
    "    \"As a supervisor, your role is to oversee a dialogue between the workers and perform  task as defined below by choosing the appropiate workesr  accordingly\"\n",
    "    \" workers: {members}.\"\n",
    "    \"Task : Based on the input you need to search the web for the topic using relevant search terms , if any insights are provided , make sure to follow them as well.\"\n",
    "    \"After getting the result based on the seacrh , you need to do an insight research based on the result.\"\n",
    "    \" Then, in the end you need to make a condensed summary of the content from previous steps, return the summary it as a result\"\n",
    "    \" Once all steps are complete,\"\n",
    "    \" indicate with 'FINISH'.\"\n",
    ")\n",
    "\n",
    "options = [\"FINISH\"] + members\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\"next\": {\"title\": \"Next\", \"anyOf\": [{\"enum\": options}] }},\n",
    "        \"required\": [\"next\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    (\"system\", \"Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}\"),\n",
    "]).partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "supervisor_chain = (prompt | llm.bind_functions(functions=[function_def], function_call=\"route\") | JsonOutputFunctionsParser())\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "search_agent = create_agent(llm, tools, \"You are a web searcher. Search the internet for information.\")\n",
    "search_node = functools.partial(agent_node, agent=search_agent, name=\"Web_Searcher\")\n",
    "\n",
    "insights_research_agent = create_agent(llm, tools, \n",
    "        \"\"\"You are a Insight Researcher. Do step by step. \n",
    "        Based on the provided content first identify the list of relevant sub topics based on the main topic,\n",
    "        then search internet for each topic one by one\n",
    "        and finally find insights for each topic one by one.\n",
    "        Include only the insights  in the final response\n",
    "        \"\"\")\n",
    "insights_research_node = functools.partial(agent_node, agent=insights_research_agent, name=\"Insight_Researcher\")\n",
    "\n",
    "\n",
    "summary_agent = create_agent(llm, tools, \"You are an expert content summariser and have a lot of professional experience in the media. Given the content make a condensed summary of the content relevant to the topic. Make sure the summary is worthy of reading and is interesting and engaging and can be posted as a content on any social site.\")\n",
    "summary_node = functools.partial(agent_node, agent=summary_agent, name=\"Summariser\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Web_Searcher\", search_node)\n",
    "workflow.add_node(\"Insight_Researcher\", insights_research_node)\n",
    "workflow.add_node(\"Summariser\", summary_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_chain)\n",
    "\n",
    "\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_graph(title,user_insight):\n",
    "    input_message=title+\" \"+user_insight\n",
    "    response = graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=input_message)]\n",
    "    })\n",
    "    #print(json.dumps(response['messages'][1].content, indent=2))\n",
    "    print(response)\n",
    "    return json.dumps(response['messages'][-1].content, indent=2)\n",
    "    #summary_markdown = response['messages'][1].content\n",
    "    #summary_text = markdown_to_text(summary_markdown)\n",
    "    #print(summary_text)\n",
    "    #return summary_text\n",
    "\n",
    "#outputs = gr.Textbox(label=\"outputs\")\n",
    "\n",
    "demo = gr.Interface(fn=run_graph, inputs=[\"text\",\"text\"], outputs=gr.components.Markdown())\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d927d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using chroma database\n",
    "\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "import gradio as gr\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph Research Agents\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\", api_key=open_ai_api_key)\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(api_key=open_ai_api_key)\n",
    "vector_store = Chroma(embedding_function=embeddings)\n",
    "\n",
    "\n",
    "@tool(\"internet_search\", return_direct=False)\n",
    "def internet_search(query: str) -> str:\n",
    "    \"\"\"Searches the internet using DuckDuckGo.\"\"\"\n",
    "    with DDGS() as ddgs:\n",
    "        results = [r['body'] for r in ddgs.text(query, max_results=3)]\n",
    "        return results if results else \"No results found.\"\n",
    "\n",
    "@tool(\"process_content\", return_direct=False)\n",
    "def process_content(url: str) -> str:\n",
    "    \"\"\"Processes content from a webpage.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "tools = [internet_search, process_content]\n",
    "\n",
    "\n",
    "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    # Store intermediate result in vector store\n",
    "    text = result[\"output\"]\n",
    "    vector_store.add_texts([text])\n",
    "    return {\"messages\": [HumanMessage(content=text, name=name)]}\n",
    "\n",
    "\n",
    "members = [\"Web_Searcher\", \"Insight_Researcher\", \"Summariser\"]\n",
    "system_prompt = (\n",
    "    \"As a supervisor, your role is to oversee a dialogue between the workers and perform tasks as defined below by choosing the appropriate workers accordingly. \"\n",
    "    \"Workers: {members}. \"\n",
    "    \"Task: Based on the input, you need to search the web for the topic using relevant search terms. \"\n",
    "    \"After getting the result based on the search, you need to do insight research based on the result. \"\n",
    "    \"Once all steps are complete, indicate with 'FINISH'.\"\n",
    ")\n",
    "\n",
    "options = [\"FINISH\"] + members\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\"next\": {\"title\": \"Next\", \"anyOf\": [{\"enum\": options}] }},\n",
    "        \"required\": [\"next\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    (\"system\", \"Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}\"),\n",
    "]).partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "supervisor_chain = (prompt | llm.bind_functions(functions=[function_def], function_call=\"route\") | JsonOutputFunctionsParser())\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "search_agent = create_agent(llm, tools, \"You are a web searcher. Search the internet for information.\")\n",
    "search_node = functools.partial(agent_node, agent=search_agent, name=\"Web_Searcher\")\n",
    "\n",
    "insights_research_agent = create_agent(llm, tools, \n",
    "        \"\"\"You are an Insight Researcher. Do step by step. \n",
    "        Based on the provided content, first identify the list of relevant subtopics based on the main topic,\n",
    "        then search the internet for each topic one by one,\n",
    "        and finally find insights for each topic one by one.\n",
    "        Include only the insights in the final response.\n",
    "        \"\"\")\n",
    "insights_research_node = functools.partial(agent_node, agent=insights_research_agent, name=\"Insight_Researcher\")\n",
    "\n",
    "summary_agent = create_agent(llm, tools, \"You are an expert content summarizer and have a lot of professional experience in the media. Given the content, make a condensed summary of the content relevant to the topic. Make sure the summary is worthy of reading and is interesting and engaging and can be posted as content on any social site.\")\n",
    "summary_node = functools.partial(agent_node, agent=summary_agent, name=\"Summariser\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Web_Searcher\", search_node)\n",
    "workflow.add_node(\"Insight_Researcher\", insights_research_node)\n",
    "workflow.add_node(\"Summariser\", summary_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_chain)\n",
    "\n",
    "\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "def generate_summarization_prompt(texts):\n",
    "    prompt = (\n",
    "        \"You are an expert content summarizer. Given the following texts, create a condensed, \"\n",
    "        \"information-dense summary that connects all the subtopics. The summary should be engaging and suitable for posting as content on any social site.\\n\\n\"\n",
    "        \"Texts:\\n\" + \"\\n\\n\".join(texts) + \"\\n\\nSummary:\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def run_graph(title, user_insight):\n",
    "    input_message = title + \" \" + user_insight\n",
    "    response = graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=input_message)]\n",
    "    })\n",
    "\n",
    "\n",
    "    texts = [doc.page_content for doc in vector_store.similarity_search(input_message, k=10)]\n",
    "\n",
    "\n",
    "    summarization_prompt = generate_summarization_prompt(texts)\n",
    "\n",
    "\n",
    "    summary_response = llm.invoke(summarization_prompt)\n",
    "    parser = StrOutputParser()\n",
    "    summary_parse_response=parser.invoke(summary_response)\n",
    "   \n",
    "    print(summary_parse_response)\n",
    "    return summary_parse_response\n",
    "\n",
    "outputs = gr.Textbox(label=\"outputs\")\n",
    "demo = gr.Interface(fn=run_graph, inputs=[\"text\", \"text\"], outputs=outputs)\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2f7b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd60e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb90b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab65cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d242d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a109a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7b6d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2115ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a8edb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea16651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
